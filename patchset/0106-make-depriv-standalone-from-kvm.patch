From 78e3b3ffda261c71cc3dc694c9662a6a7bb7b9cb Mon Sep 17 00:00:00 2001
From: Xin Li <fantry@msn.com>
Date: Sat, 5 Sep 2020 18:47:16 -0700
Subject: [PATCH 106/140] make depriv standalone from kvm

---
 arch/x86/Kbuild                               |   2 +
 arch/x86/Kconfig                              |  24 ++
 arch/x86/depriv/Kconfig                       |  37 ++
 arch/x86/depriv/Makefile                      |  18 +
 arch/x86/{kvm/vmx => depriv}/depriv.h         |   0
 arch/x86/{kvm => depriv}/vmx/depriv.c         | 343 +++++++++++++-----
 arch/x86/{kvm => depriv}/vmx/depriv_entry.S   |  56 ++-
 arch/x86/{kvm => depriv}/vmx/depriv_handler.c |   0
 .../{kvm => depriv}/vmx/depriv_validator.c    |   5 +
 arch/x86/depriv/vmx/vmx.h                     | 325 +++++++++++++++++
 arch/x86/depriv/x86.c                         |   9 +
 arch/x86/include/asm/depriv.h                 |   2 +
 arch/x86/kvm/Kconfig                          |  13 -
 arch/x86/kvm/Makefile                         |   1 -
 arch/x86/kvm/vmx/test_depriv.sh               |  17 -
 arch/x86/kvm/vmx/vmx.c                        |  18 -
 tools/testing/selftests/depriv/test_depriv.sh |  17 +
 virt/depriv/Kconfig                           |   5 +
 virt/depriv/depriv_main.c                     |   7 +
 virt/kvm/kvm_main.c                           |   4 -
 20 files changed, 765 insertions(+), 138 deletions(-)
 create mode 100644 arch/x86/depriv/Kconfig
 create mode 100644 arch/x86/depriv/Makefile
 rename arch/x86/{kvm/vmx => depriv}/depriv.h (100%)
 rename arch/x86/{kvm => depriv}/vmx/depriv.c (80%)
 rename arch/x86/{kvm => depriv}/vmx/depriv_entry.S (64%)
 rename arch/x86/{kvm => depriv}/vmx/depriv_handler.c (100%)
 rename arch/x86/{kvm => depriv}/vmx/depriv_validator.c (99%)
 create mode 100644 arch/x86/depriv/vmx/vmx.h
 create mode 100644 arch/x86/depriv/x86.c
 delete mode 100755 arch/x86/kvm/vmx/test_depriv.sh
 create mode 100755 tools/testing/selftests/depriv/test_depriv.sh
 create mode 100644 virt/depriv/Kconfig
 create mode 100644 virt/depriv/depriv_main.c

diff --git a/arch/x86/Kbuild b/arch/x86/Kbuild
index f384cb1a4f7a..44e7bea7cee0 100644
--- a/arch/x86/Kbuild
+++ b/arch/x86/Kbuild
@@ -3,6 +3,8 @@ obj-y += entry/
 
 obj-$(CONFIG_PERF_EVENTS) += events/
 
+obj-$(CONFIG_DEPRIV) += depriv/
+
 obj-$(CONFIG_KVM) += kvm/
 
 # Xen paravirtualization support
diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 407533c835fe..3f725cac8025 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -220,6 +220,7 @@ config X86
 	select HAVE_KPROBES_ON_FTRACE
 	select HAVE_FUNCTION_ERROR_INJECTION
 	select HAVE_KRETPROBES
+	select HAVE_DEPRIV			if X86_64
 	select HAVE_KVM
 	select HAVE_LIVEPATCH			if X86_64
 	select HAVE_MIXED_BREAKPOINTS_REGS
@@ -2882,6 +2883,29 @@ config HAVE_ATOMIC_IOMAP
 	def_bool y
 	depends on X86_32
 
+source "drivers/firmware/Kconfig"
+
+source "virt/depriv/Kconfig"
+
+source "virt/kvm/Kconfig"
+
+menuconfig VIRTUALIZATION
+	bool "Virtualization"
+	depends on HAVE_DEPRIV || HAVE_KVM || X86
+	default y
+	help
+	  Say Y here to get to see options for using your Linux host to run other
+	  operating systems inside virtual machines (guests).
+	  This option alone does not add any kernel code.
+
+	  If you say N, all options in this submenu will be skipped and disabled.
+
+if VIRTUALIZATION
+
+source "arch/x86/depriv/Kconfig"
+
 source "arch/x86/kvm/Kconfig"
 
+endif # VIRTUALIZATION
+
 source "arch/x86/Kconfig.assembler"
diff --git a/arch/x86/depriv/Kconfig b/arch/x86/depriv/Kconfig
new file mode 100644
index 000000000000..bd0f24de4d7e
--- /dev/null
+++ b/arch/x86/depriv/Kconfig
@@ -0,0 +1,37 @@
+# SPDX-License-Identifier: GPL-2.0
+#
+# Depriv configuration
+#
+
+if VIRTUALIZATION
+
+config DEPRIV
+	tristate "Deprivilege Linux using hardware virtualization extensions"
+	depends on HAVE_DEPRIV
+	help
+	  Deprivilege Linux kernel using hardware virtualization extensions.
+
+	  If unsure, say N.
+
+config DEPRIV_WERROR
+	bool "Compile depriv with -Werror"
+	# KASAN may cause the build to fail due to larger frames
+	default y if X86_64 && !KASAN
+	# We use the dependency on !COMPILE_TEST to not be enabled
+	# blindly in allmodconfig or allyesconfig configurations
+	depends on (X86_64 && !KASAN) || !COMPILE_TEST
+	depends on EXPERT
+
+config DEPRIV_INTEL
+	tristate "Deprivilege for Intel"
+	depends on X86_64 && DEPRIV
+	help
+	  Run Linux in VMX non-root mode.
+
+config DEPRIV_AMD
+	tristate "Deprivilege for AMD"
+	depends on X86_64 && DEPRIV
+	help
+	  Run Linux in AMD SVM.
+
+endif # VIRTUALIZATION
diff --git a/arch/x86/depriv/Makefile b/arch/x86/depriv/Makefile
new file mode 100644
index 000000000000..4f9af271be83
--- /dev/null
+++ b/arch/x86/depriv/Makefile
@@ -0,0 +1,18 @@
+# SPDX-License-Identifier: GPL-2.0
+
+ccflags-y	+= -Iarch/x86/depriv -Iarch/x86
+ccflags-$(CONFIG_DEPRIV_WERROR)	+= -Werror
+
+ifeq ($(CONFIG_FRAME_POINTER),y)
+OBJECT_FILES_NON_STANDARD_depriv_entry.o := y
+endif
+
+DEPRIV := ../../../virt/depriv
+
+#depriv-y	+= $(DERPIV)/depriv_main.o
+#depriv-y	+= x86.o
+
+depriv-intel-y	+= vmx/depriv.o vmx/depriv_entry.o vmx/depriv_handler.o vmx/depriv_validator.o
+
+#obj-$(CONFIG_DEPRIV)		+= depriv.o
+obj-$(CONFIG_DEPRIV_INTEL)	+= depriv-intel.o
diff --git a/arch/x86/kvm/vmx/depriv.h b/arch/x86/depriv/depriv.h
similarity index 100%
rename from arch/x86/kvm/vmx/depriv.h
rename to arch/x86/depriv/depriv.h
diff --git a/arch/x86/kvm/vmx/depriv.c b/arch/x86/depriv/vmx/depriv.c
similarity index 80%
rename from arch/x86/kvm/vmx/depriv.c
rename to arch/x86/depriv/vmx/depriv.c
index 12ffed7dfde7..39b15b7ae309 100644
--- a/arch/x86/kvm/vmx/depriv.c
+++ b/arch/x86/depriv/vmx/depriv.c
@@ -13,6 +13,7 @@
 #include <asm/atomic.h>
 #include <asm/debugreg.h>
 #include <asm/insn.h>
+#include <asm/tlbflush.h>
 
 #include "vmx.h"
 
@@ -70,14 +71,32 @@ module_param(intercept_cr3, bool, S_IRUGO);
 
 #define DEPRIV_INVALID_HOST_CR3_TARGET_COUNT	0x100000
 
-static struct vmcs_config depriv_vmcs_conf;
-static unsigned long depriv_task_cr3_pa;
-struct cpumask depriv_cpu_root_mode_mask;
-static struct semaphore depriv_cpu_count_sema;
+struct vmcs_config depriv_vmcs_config;
+
+static struct cpumask cpu_vmx_operation_mask;
 static atomic_t depriv_cpu_count;
-static bool depriv_cleanup = false;
+static struct semaphore depriv_cpu_count_sema;
+static struct cpumask cpu_depriv_mode_mask;
+static bool volatile depriv_cleanup = false;
+
+static DEFINE_PER_CPU(struct vmcs *, vmxarea) = NULL;
+static DEFINE_PER_CPU(struct vmcs *, depriv_vmcs) = NULL;
 
-static DEFINE_PER_CPU(struct vmcs *, depriv_vmcs);
+/*
+ * We maintain a per-CPU linked-list of VMCS loaded on that CPU.
+ */
+static DEFINE_PER_CPU(struct list_head, loaded_vmcss_on_cpu);
+
+static inline bool cpu_has_load_perf_global_ctrl(void)
+{
+	return (depriv_vmcs_config.vmentry_ctrl & VM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL) &&
+	       (depriv_vmcs_config.vmexit_ctrl & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL);
+}
+
+static void free_vmcs(struct vmcs *vmcs)
+{
+	free_pages((unsigned long)vmcs, depriv_vmcs_config.order);
+}
 
 void dump_va_page_table_entry(unsigned long va);
 
@@ -100,7 +119,7 @@ static __init int adjust_vmx_controls(u32 ctl_min, u32 ctl_opt,
 	return 0;
 }
 
-static int __init setup_depriv_vmcs_config(void)
+static int __init setup_vmcs_config(void)
 {
 	u32 min, opt, min2, opt2;
 	u32 _pin_based_exec_control = 0;
@@ -108,8 +127,9 @@ static int __init setup_depriv_vmcs_config(void)
 	u32 _cpu_based_2nd_exec_control = 0;
 	u32 _vmexit_control = 0;
 	u32 _vmentry_control = 0;
+	u32 vmx_msr_low = 0, vmx_msr_high = 0;
 
-	memset(&depriv_vmcs_conf, 0, sizeof(depriv_vmcs_conf));
+	memset(&depriv_vmcs_config, 0, sizeof(depriv_vmcs_config));
 	min = 0;
 	opt = CPU_BASED_USE_MSR_BITMAPS |
 	      CPU_BASED_ACTIVATE_SECONDARY_CONTROLS;
@@ -177,43 +197,105 @@ static int __init setup_depriv_vmcs_config(void)
 				&_vmentry_control) < 0)
 		return -EIO;
 
-	depriv_vmcs_conf.pin_based_exec_ctrl = _pin_based_exec_control;
-	depriv_vmcs_conf.cpu_based_exec_ctrl = _cpu_based_exec_control;
-	depriv_vmcs_conf.cpu_based_2nd_exec_ctrl = _cpu_based_2nd_exec_control;
-	depriv_vmcs_conf.vmexit_ctrl         = _vmexit_control;
-	depriv_vmcs_conf.vmentry_ctrl        = _vmentry_control;
+	rdmsr(MSR_IA32_VMX_BASIC, vmx_msr_low, vmx_msr_high);
+
+	/* IA-32 SDM Vol 3B: VMCS size is never greater than 4kB. */
+	if ((vmx_msr_high & 0x1fff) > PAGE_SIZE)
+		return -EIO;
+
+	/* IA-32 SDM Vol 3B: 64-bit CPUs always have VMX_BASIC_MSR[48]==0. */
+	if (vmx_msr_high & (1u<<16))
+		return -EIO;
+
+	/* Require Write-Back (WB) memory type for VMCS accesses. */
+	if (((vmx_msr_high >> 18) & 15) != 6)
+		return -EIO;
+
+	depriv_vmcs_config.size = vmx_msr_high & 0x1fff;
+	depriv_vmcs_config.order = get_order(depriv_vmcs_config.size);
+	depriv_vmcs_config.basic_cap = vmx_msr_high & ~0x1fff;
+
+	depriv_vmcs_config.revision_id = vmx_msr_low;
+
+	depriv_vmcs_config.pin_based_exec_ctrl = _pin_based_exec_control;
+	depriv_vmcs_config.cpu_based_exec_ctrl = _cpu_based_exec_control;
+	depriv_vmcs_config.cpu_based_2nd_exec_ctrl = _cpu_based_2nd_exec_control;
+	depriv_vmcs_config.vmexit_ctrl         = _vmexit_control;
+	depriv_vmcs_config.vmentry_ctrl        = _vmentry_control;
 
 	pr_info("depriv: pin based controls: %#x\n",
-		depriv_vmcs_conf.pin_based_exec_ctrl);
+		depriv_vmcs_config.pin_based_exec_ctrl);
 	pr_info("depriv: processor based controls: %#x\n",
-		depriv_vmcs_conf.cpu_based_exec_ctrl);
+		depriv_vmcs_config.cpu_based_exec_ctrl);
 	pr_info("depriv: processor based 2nd controls: %#x\n",
-		depriv_vmcs_conf.cpu_based_2nd_exec_ctrl);
+		depriv_vmcs_config.cpu_based_2nd_exec_ctrl);
 	pr_info("depriv: vm exit controls: %#x\n",
-		depriv_vmcs_conf.vmexit_ctrl);
+		depriv_vmcs_config.vmexit_ctrl);
 	pr_info("depriv: vm entry controls: %#x\n",
-		depriv_vmcs_conf.vmentry_ctrl);
+		depriv_vmcs_config.vmentry_ctrl);
 
 	return 0;
 }
 
+#define vmx_insn_failed(fmt...)		\
+do {					\
+	WARN_ONCE(1, fmt);		\
+	pr_warn_ratelimited(fmt);	\
+} while (0)
+
+asmlinkage void vmread_error(unsigned long field, bool fault)
+{
+	if (fault)
+		BUG();
+	else
+		vmx_insn_failed("depriv: vmread failed: field=%lx\n", field);
+}
+
+noinline void vmwrite_error(unsigned long field, unsigned long value)
+{
+	vmx_insn_failed("depriv: vmwrite failed: field=%lx val=%lx err=%d\n",
+			field, value, vmcs_read32(VM_INSTRUCTION_ERROR));
+}
+
+noinline void vmclear_error(struct vmcs *vmcs, u64 phys_addr)
+{
+	vmx_insn_failed("depriv: vmclear failed: %p/%llx\n", vmcs, phys_addr);
+}
+
+noinline void vmptrld_error(struct vmcs *vmcs, u64 phys_addr)
+{
+	vmx_insn_failed("depriv: vmptrld failed: %p/%llx\n", vmcs, phys_addr);
+}
+
+noinline void invvpid_error(unsigned long ext, u16 vpid, gva_t gva)
+{
+	vmx_insn_failed("depriv: invvpid failed: ext=0x%lx vpid=%u gva=0x%lx\n",
+			ext, vpid, gva);
+}
+
+noinline void invept_error(unsigned long ext, u64 eptp, gpa_t gpa)
+{
+	vmx_insn_failed("depriv: invept failed: ext=0x%lx eptp=%llx gpa=0x%llx\n",
+			ext, eptp, gpa);
+}
+
 static void vmx_depriv_cpu_controls(void)
 {
 	vmcs_write32(PIN_BASED_VM_EXEC_CONTROL,
-		     depriv_vmcs_conf.pin_based_exec_ctrl);
+		     depriv_vmcs_config.pin_based_exec_ctrl);
 	vmcs_write32(CPU_BASED_VM_EXEC_CONTROL,
-		     depriv_vmcs_conf.cpu_based_exec_ctrl);
+		     depriv_vmcs_config.cpu_based_exec_ctrl);
 
 	if (cpu_has_secondary_exec_ctrls()) {
 		vmcs_write32(SECONDARY_VM_EXEC_CONTROL,
-		     depriv_vmcs_conf.cpu_based_2nd_exec_ctrl);
+		     depriv_vmcs_config.cpu_based_2nd_exec_ctrl);
 	}
 
 	vmcs_write32(VM_EXIT_CONTROLS,
-		     depriv_vmcs_conf.vmexit_ctrl |
+		     depriv_vmcs_config.vmexit_ctrl |
 		     VM_EXIT_HOST_ADDR_SPACE_SIZE);
 	vmcs_write32(VM_ENTRY_CONTROLS,
-		     depriv_vmcs_conf.vmentry_ctrl);
+		     depriv_vmcs_config.vmentry_ctrl);
 
 	vmcs_write32(EXCEPTION_BITMAP, exception_bitmap);
 	vmcs_write32(PAGE_FAULT_ERROR_CODE_MASK, 0);
@@ -497,6 +579,45 @@ static void vmx_depriv_cpu_state(void)
 	vmcs_writel(HOST_RIP, (unsigned long)vmx_depriv_vmexit);
 }
 
+static void vmclear_local_loaded_vmcss(void)
+{
+	int cpu = raw_smp_processor_id();
+	struct loaded_vmcs *v, *n;
+
+	list_for_each_entry_safe(v, n, &per_cpu(loaded_vmcss_on_cpu, cpu),
+				 loaded_vmcss_on_cpu_link) {
+		vmcs_clear(v->vmcs);
+		v->launched = 0;
+	}
+}
+
+static void vmx_cpu_vmxoff(void)
+{
+	asm volatile("vmxoff");
+
+	intel_pt_handle_vmx(0);
+	cr4_clear_bits(X86_CR4_VMXE);
+}
+
+static void hardware_disable(void)
+{
+	int cpu = raw_smp_processor_id();
+	struct vmcs *vmcs = per_cpu(vmxarea, cpu);
+
+	if (!vmcs)
+		return;
+
+	vmclear_local_loaded_vmcss();
+	vmx_cpu_vmxoff();
+	free_vmcs(vmcs);
+
+	BUG_ON(!cpumask_test_cpu(cpu, &cpu_vmx_operation_mask));
+	cpumask_clear_cpu(cpu, &cpu_vmx_operation_mask);
+
+	if (atomic_dec_and_test(&depriv_cpu_count))
+		up(&depriv_cpu_count_sema);
+}
+
 /*
  * this function must be executed in root mode.
  */
@@ -506,9 +627,6 @@ static void vmx_repriv_cpu_release_resources(void)
 	void *host_cpu_state = per_cpu(depriv_cpu_state, cpu);
 	struct vmcs *vmcs = per_cpu(depriv_vmcs, cpu);
 
-	if (!depriv_cleanup)
-		return;
-
 	if (host_cpu_state) {
 		per_cpu(depriv_cpu_state, cpu) = NULL;
 		memset(host_cpu_state, 0, DEPRIV_CPU_STATE_BUFFER_SIZE);
@@ -523,8 +641,7 @@ static void vmx_repriv_cpu_release_resources(void)
 		pr_info("depriv: repriv cpu%d released root mode VMCS\n", cpu);
 	}
 
-	if (atomic_dec_and_test(&depriv_cpu_count))
-		up(&depriv_cpu_count_sema);
+	hardware_disable();
 }
 
 static inline unsigned long depriv_iret_trampoline_stack(int cpu)
@@ -532,7 +649,7 @@ static inline unsigned long depriv_iret_trampoline_stack(int cpu)
 	return get_cpu_entry_area(cpu)->tss.x86_tss.ist[IST_INDEX_NMI] - 64 * 8;
 }
 
-int vmx_depriv(bool launch);
+int asm_vmx_depriv(bool launch);
 void vmx_depriv_rip(void);
 
 void vmx_validate_guest_state(void);
@@ -540,7 +657,7 @@ void vmx_validate_guest_state(void);
 /*
  * WARNING: must be called with interrupt disabled!
  */
-static bool __vmx_depriv_enter(bool launch)
+static bool __vmx_depriv(bool launch)
 {
 	int cpu = raw_smp_processor_id();
 	unsigned long rip, rsp, rflags;
@@ -552,7 +669,7 @@ static bool __vmx_depriv_enter(bool launch)
 	vmcs_writel(GUEST_RIP, rip);
 
 	asm volatile("mov %%rsp,%0" : "=m"(rsp));
-	// reserve extra 8 bytes for RIP pushed to stack when calling vmx_depriv
+	// reserve extra 8 bytes for RIP pushed to stack when calling asm_vmx_depriv
 	rsp -= 8;
 	vmcs_writel(GUEST_RSP, rsp);
 
@@ -568,15 +685,11 @@ static bool __vmx_depriv_enter(bool launch)
 		pr_info("depriv: cpu%d (%ld) deprivileging: rip: %#lx rsp: %#lx\n", cpu, c, rip, rsp);
 
 	/*
-	 * Should we save/restore general purpose registers around vmx_depriv?
+	 * Should we save/restore general purpose registers around asm_vmx_depriv?
 	 */
-	depriv_result = vmx_depriv(launch);
-	if (launch)
-		atomic_inc(&depriv_cpu_count);
+	depriv_result = asm_vmx_depriv(launch);
 	if (!depriv_result) { // switched to non-root mode
-		if (!launch)
-			cpumask_clear_cpu(cpu, &depriv_cpu_root_mode_mask);
-
+		cpumask_set_cpu(cpu, &cpu_depriv_mode_mask);
 		return true;
 	}
 
@@ -595,6 +708,77 @@ static bool __vmx_depriv_enter(bool launch)
 	return false;
 }
 
+static struct vmcs *alloc_vmcs(void)
+{
+	int cpu = raw_smp_processor_id();
+	int node = cpu_to_node(cpu);
+	struct page *pages;
+	struct vmcs *vmcs;
+
+	pages = __alloc_pages_node(node, GFP_KERNEL, depriv_vmcs_config.order);
+	if (!pages)
+		return NULL;
+
+	vmcs = page_address(pages);
+	memset(vmcs, 0, depriv_vmcs_config.size);
+	vmcs->hdr.revision_id = depriv_vmcs_config.revision_id;
+	return vmcs;
+}
+
+static int vmx_cpu_vmxon(u64 vmxon_pointer)
+{
+	u64 msr;
+
+	cr4_set_bits(X86_CR4_VMXE);
+	intel_pt_handle_vmx(1);
+
+	asm_volatile_goto("1: vmxon %[vmxon_pointer]\n\t"
+			  _ASM_EXTABLE(1b, %l[fault])
+			  : : [vmxon_pointer] "m"(vmxon_pointer)
+			  : : fault);
+	return 0;
+
+fault:
+	WARN_ONCE(1, "depriv: VMXON faulted, MSR_IA32_FEAT_CTL (0x3a) = 0x%llx\n",
+		  rdmsrl_safe(MSR_IA32_FEAT_CTL, &msr) ? 0xdeadbeef : msr);
+	intel_pt_handle_vmx(0);
+	cr4_clear_bits(X86_CR4_VMXE);
+
+	return -EFAULT;
+}
+
+static int hardware_enable(void)
+{
+	int cpu = raw_smp_processor_id();
+	struct vmcs *vmcs;
+	int r;
+
+	if (cr4_read_shadow() & X86_CR4_VMXE)
+		return -EBUSY;
+
+	vmcs = alloc_vmcs();
+	if (!vmcs)
+		return -ENOMEM;
+
+	r = vmx_cpu_vmxon(__pa(vmcs));
+	if (r) {
+		free_vmcs(vmcs);
+		return r;
+	}
+
+	pr_info("depriv: VMX enabled on cpu%d\n", cpu);
+	ept_sync_global();
+
+	atomic_inc(&depriv_cpu_count);
+	BUG_ON(cpumask_test_cpu(cpu, &cpu_vmx_operation_mask));
+	cpumask_set_cpu(cpu, &cpu_vmx_operation_mask);
+
+	BUG_ON(per_cpu(vmxarea, cpu));
+	per_cpu(vmxarea, cpu) = vmcs;
+	INIT_LIST_HEAD(&per_cpu(loaded_vmcss_on_cpu, cpu));
+	return 0;
+}
+
 static void vmx_depriv_cpu(void *info)
 {
 	int cpu = raw_smp_processor_id();
@@ -603,15 +787,18 @@ static void vmx_depriv_cpu(void *info)
 	struct page *page = NULL;
 	void *host_cpu_state = NULL;
 	void *host_cr3_va = NULL;
+	unsigned long cr3_pa = (unsigned long)info;
 	void *msr_bitmap = NULL;
 	unsigned long host_rsp;
+	int r;
 
-	if (!(depriv_vmcs_conf.cpu_based_exec_ctrl & CPU_BASED_USE_MSR_BITMAPS)) {
-		pr_err("depriv: MSR bitmap not available on cpu%d\n", cpu);
+	r = hardware_enable();
+	if (r) {
+		pr_err("depriv: vmxon error %d, unable to enable VMX on cpu%d\n", r, cpu);
 		goto error;
 	}
 
-	vmcs = alloc_vmcs_cpu(false, cpu, GFP_KERNEL);
+	vmcs = alloc_vmcs();
 	if (!vmcs) {
 		pr_err("depriv: unable to allocate VMCS for cpu%d\n", cpu);
 		goto error;
@@ -636,7 +823,7 @@ static void vmx_depriv_cpu(void *info)
 
 	// last 2 pages of host state
 	host_cr3_va = host_cpu_state + DEPRIV_CPU_STATE_ROOT_PGD;
-	memcpy(host_cr3_va, __va(depriv_task_cr3_pa), PAGE_SIZE);
+	memcpy(host_cr3_va, __va(cr3_pa), PAGE_SIZE);
 	vmcs_writel(HOST_CR3, __pa(host_cr3_va));
 
 	// the 2nd page of host state
@@ -663,7 +850,7 @@ static void vmx_depriv_cpu(void *info)
 	}
 
 	/* switching to non-root mode */
-	if (__vmx_depriv_enter(true))
+	if (__vmx_depriv(true))
 		return;
 
 error:
@@ -818,12 +1005,12 @@ static inline void vmx_repriv_cpu_desc_tables(void)
 /*
  * WARNING: must be called with interrupt disabled!
  */
-static void vmx_depriv_exit(void)
+static void vmx_repriv(void)
 {
 	asm volatile("vmcall");
 }
 
-void vmx_repriv_cpu(void *info)
+static void vmx_repriv_cpu(void *info)
 {
 	int cpu = raw_smp_processor_id();
 	void *host_cpu_state = per_cpu(depriv_cpu_state, cpu);
@@ -833,7 +1020,7 @@ void vmx_repriv_cpu(void *info)
 		return;
 	}
 
-	vmx_depriv_exit();
+	vmx_repriv();
 
 	// switched to root mode
 	pr_info("depriv: cpu%d reprivileged\n", cpu);
@@ -858,8 +1045,6 @@ void vmx_repriv_cpu(void *info)
 	DEPRIV_IRET_STACK_SS(base)	= vmcs_read16(GUEST_SS_SELECTOR);	\
 } while (0)
 
-void asm_depriv_exit(void);
-
 static void vmx_depriv_debug_with_non_root_mode(void)
 {
 	int cpu = raw_smp_processor_id();
@@ -938,8 +1123,6 @@ bool vmx_repriv_cpu_state(void)
 		return false;
 	}
 
-	cpumask_set_cpu(cpu, &depriv_cpu_root_mode_mask);
-
 	if (depriv_cleanup) {
 		pr_info("depriv: cpu%d switching to root mode GS base %#lx kernel GS base %#lx\n",
 			cpu, read_msr(MSR_GS_BASE), read_msr(MSR_KERNEL_GS_BASE));
@@ -951,7 +1134,7 @@ bool vmx_repriv_cpu_state(void)
 
 #define DEPRIV_CONTINUE_IN_NON_ROOT_MODE(ins_len) do {				\
 	vmcs_writel(GUEST_RIP, rip + ins_len);					\
-	cpumask_clear_cpu(cpu, &depriv_cpu_root_mode_mask);			\
+	cpumask_set_cpu(cpu, &cpu_depriv_mode_mask);				\
 	return true;								\
 } while (0)
 
@@ -973,7 +1156,7 @@ bool vmx_depriv_vmexit_handler(unsigned long *regs)
 	u32 reason = vmcs_read32(VM_EXIT_REASON), insn_len = 0;
 	char insn[64];
 
-	cpumask_set_cpu(cpu, &depriv_cpu_root_mode_mask);
+	cpumask_clear_cpu(cpu, &cpu_depriv_mode_mask);
 
 	regs[VCPU_REGS_RSP] = rsp;
 
@@ -994,7 +1177,7 @@ bool vmx_depriv_vmexit_handler(unsigned long *regs)
 
 	if (!(counter % log_mod))
 		pr_info("depriv: cpu%d (%ld) exit reason: %d cpu mask: %*pb[l]\n",
-			cpu, counter, reason, cpumask_pr_args(&depriv_cpu_root_mode_mask));
+			cpu, counter, reason, cpumask_pr_args(&cpu_depriv_mode_mask));
 
 	switch (reason) {
 	case EXIT_REASON_CPUID:
@@ -1024,7 +1207,7 @@ bool vmx_depriv_vmexit_handler(unsigned long *regs)
 
 	case EXIT_REASON_VMCALL:
 		pr_debug("depriv: cpu%d (%ld) exit reason: %d cpu mask: %*pb[l]\n",
-			 cpu, counter, reason, cpumask_pr_args(&depriv_cpu_root_mode_mask));
+			 cpu, counter, reason, cpumask_pr_args(&cpu_depriv_mode_mask));
 
 		insn_len = vmcs_read32(VM_EXIT_INSTRUCTION_LEN);
 
@@ -1050,43 +1233,35 @@ bool vmx_depriv_vmexit_handler(unsigned long *regs)
 	}
 }
 
-static int depriv_task(void *unused)
+static bool vmx_depriv(void)
 {
-	depriv_task_cr3_pa = read_cr3_pa();
-	pr_debug("depriv: depriv task cr3: %lx\n", depriv_task_cr3_pa);
-
-	sema_init(&depriv_cpu_count_sema, 0);
-	on_each_cpu(vmx_depriv_cpu, NULL, 0);
-	return 0;
+	return __vmx_depriv(false);
 }
 
-static bool vmx_depriv_enter(void)
+static int __init vmx_depriv_init(void)
 {
-	return __vmx_depriv_enter(false);
-}
-
-void __init vmx_depriv_host(void)
-{
-	if (setup_depriv_vmcs_config()) {
+	int r = setup_vmcs_config();
+	if (r) {
 		pr_err("depriv: error setting up deprivilege VMCS config\n");
-		return;
+		return r;
 	}
 
-	depriv_ops.enter = vmx_depriv_enter;
-	depriv_ops.exit = vmx_depriv_exit;
+	depriv_ops.enter = vmx_depriv;
+	depriv_ops.exit = vmx_repriv;
 
-	kthread_run(depriv_task, NULL, "depriv_task");
-}
+	sema_init(&depriv_cpu_count_sema, 0);
+	on_each_cpu(vmx_depriv_cpu, (void *)read_cr3_pa(), 0);
 
-void vmx_depriv_signal_cleanup(void)
-{
-	depriv_cleanup = true;
+	if (!atomic_read(&depriv_cpu_count))
+		return -EIO;
+
+	pr_info("depriv: successfully initialized\n");
+	return 0;
 }
 
-void vmx_repriv_host(void)
+static void __exit vmx_depriv_exit(void)
 {
 	int c = atomic_read(&depriv_cpu_count);
-
 	if (!c) {
 		pr_info("depriv: no cpus deprivileged");
 		return;
@@ -1102,14 +1277,18 @@ void vmx_repriv_host(void)
 		msleep(100);
 	}
 
-	vmx_depriv_signal_cleanup();
-
 	pr_info("depriv: %d cpus deprivileged, reprivileging...\n", c);
+	depriv_cleanup = true;
 	on_each_cpu(vmx_repriv_cpu, NULL, 0);
 
 	if (down_interruptible(&depriv_cpu_count_sema))
 		pr_err("depriv: cpu count semaphore interrupted\n");
 
-	pr_info("depriv: %d cpus still in non-root mode\n",
-		atomic_read(&depriv_cpu_count));
+	pr_info("depriv: %d cpus still in non-root mode, cpu mask: %*pb[l]\n",
+		atomic_read(&depriv_cpu_count), cpumask_pr_args(&cpu_vmx_operation_mask));
+
+	pr_info("depriv: successfully unloaded\n");
 }
+
+module_init(vmx_depriv_init);
+module_exit(vmx_depriv_exit);
diff --git a/arch/x86/kvm/vmx/depriv_entry.S b/arch/x86/depriv/vmx/depriv_entry.S
similarity index 64%
rename from arch/x86/kvm/vmx/depriv_entry.S
rename to arch/x86/depriv/vmx/depriv_entry.S
index 4ed035db686a..7b77fb28fafc 100644
--- a/arch/x86/kvm/vmx/depriv_entry.S
+++ b/arch/x86/depriv/vmx/depriv_entry.S
@@ -3,6 +3,9 @@
 #include <asm/asm.h>
 #include <asm/kvm_vcpu_regs.h>
 #include <asm/msr-index.h>
+#include <asm/bitsperlong.h>
+
+#define WORD_SIZE (BITS_PER_LONG / 8)
 
 .macro PUSH_AND_CLEAR_ALL
 	push %r15
@@ -78,7 +81,7 @@ SYM_CODE_START(vmx_depriv_switch_to_root_mode)
 	/* XXX what if vmresume fails? */
 SYM_CODE_END(vmx_depriv_switch_to_root_mode)
 
-SYM_FUNC_START(vmx_depriv)
+SYM_FUNC_START(asm_vmx_depriv)
 	cmpb $0, %_ASM_ARG1B
 	je 1f
 
@@ -97,13 +100,13 @@ SYM_FUNC_START(vmx_depriv)
 2:	xor %rax, %rax
 	mov $1, %rax
 	ret
-SYM_FUNC_END(vmx_depriv)
+SYM_FUNC_END(asm_vmx_depriv)
 
 /*
  * vmlaunch succeeded
  */
 SYM_FUNC_START(vmx_depriv_rip)
-	/* to instruction immediately after vmx_depriv */
+	/* to instruction immediately after asm_vmx_depriv */
 	ret
 SYM_FUNC_END(vmx_depriv_rip)
 
@@ -132,3 +135,50 @@ SYM_FUNC_START(vmx_depriv_vmexit)
 	 */
 	jmp vmx_depriv_switch_to_root_mode
 SYM_FUNC_END(vmx_depriv_vmexit)
+
+
+.section .text, "ax"
+
+/**
+ * vmread_error_trampoline - Trampoline from inline asm to vmread_error()
+ * @field:	VMCS field encoding that failed
+ * @fault:	%true if the VMREAD faulted, %false if it failed
+
+ * Save and restore volatile registers across a call to vmread_error().  Note,
+ * all parameters are passed on the stack.
+ */
+SYM_FUNC_START(vmread_error_trampoline)
+	push %_ASM_BP
+	mov  %_ASM_SP, %_ASM_BP
+
+	push %_ASM_AX
+	push %_ASM_CX
+	push %_ASM_DX
+	push %rdi
+	push %rsi
+	push %r8
+	push %r9
+	push %r10
+	push %r11
+	/* Load @field and @fault to arg1 and arg2 respectively. */
+	mov 3*WORD_SIZE(%rbp), %_ASM_ARG2
+	mov 2*WORD_SIZE(%rbp), %_ASM_ARG1
+
+	call vmread_error
+
+	/* Zero out @fault, which will be popped into the result register. */
+	_ASM_MOV $0, 3*WORD_SIZE(%_ASM_BP)
+
+	pop %r11
+	pop %r10
+	pop %r9
+	pop %r8
+	pop %rsi
+	pop %rdi
+	pop %_ASM_DX
+	pop %_ASM_CX
+	pop %_ASM_AX
+	pop %_ASM_BP
+
+	ret
+SYM_FUNC_END(vmread_error_trampoline)
diff --git a/arch/x86/kvm/vmx/depriv_handler.c b/arch/x86/depriv/vmx/depriv_handler.c
similarity index 100%
rename from arch/x86/kvm/vmx/depriv_handler.c
rename to arch/x86/depriv/vmx/depriv_handler.c
diff --git a/arch/x86/kvm/vmx/depriv_validator.c b/arch/x86/depriv/vmx/depriv_validator.c
similarity index 99%
rename from arch/x86/kvm/vmx/depriv_validator.c
rename to arch/x86/depriv/vmx/depriv_validator.c
index e0d176f22195..6b6d787f8ed5 100644
--- a/arch/x86/kvm/vmx/depriv_validator.c
+++ b/arch/x86/depriv/vmx/depriv_validator.c
@@ -26,6 +26,11 @@
 #define CHECK_HOST_SEG(seg)						\
 	check((vmcs_read16(HOST_##seg##_SELECTOR) & 0x7) == 0)
 
+static inline u64 get_canonical(u64 la, u8 vaddr_bits)
+{
+	return ((int64_t)la << (64 - vaddr_bits)) >> (64 - vaddr_bits);
+}
+
 static inline bool is_canonical_address(u64 la, u64 cr4)
 {
 	return get_canonical(la, cr4 & X86_CR4_LA57 ? 57 : 48) == la;
diff --git a/arch/x86/depriv/vmx/vmx.h b/arch/x86/depriv/vmx/vmx.h
new file mode 100644
index 000000000000..68d9654ce84e
--- /dev/null
+++ b/arch/x86/depriv/vmx/vmx.h
@@ -0,0 +1,325 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef __DEPRIV_X86_VMX_H
+#define __DEPRIV_X86_VMX_H
+
+#include <asm/vmx.h>
+
+#define DE_VECTOR 0
+#define DB_VECTOR 1
+#define BP_VECTOR 3
+#define OF_VECTOR 4
+#define BR_VECTOR 5
+#define UD_VECTOR 6
+#define NM_VECTOR 7
+#define DF_VECTOR 8
+#define TS_VECTOR 10
+#define NP_VECTOR 11
+#define SS_VECTOR 12
+#define GP_VECTOR 13
+#define PF_VECTOR 14
+#define MF_VECTOR 16
+#define AC_VECTOR 17
+#define MC_VECTOR 18
+#define XM_VECTOR 19
+#define VE_VECTOR 20
+
+struct vmcs_config {
+	int size;
+	int order;
+	u32 basic_cap;
+	u32 revision_id;
+	u32 pin_based_exec_ctrl;
+	u32 cpu_based_exec_ctrl;
+	u32 cpu_based_2nd_exec_ctrl;
+	u32 vmexit_ctrl;
+	u32 vmentry_ctrl;
+};
+
+struct vmcs_hdr {
+	u32 revision_id:31;
+	u32 shadow_vmcs:1;
+};
+
+struct vmcs {
+	struct vmcs_hdr hdr;
+	u32 abort;
+	char data[];
+};
+
+static inline bool is_intr_type_n(u32 intr_info, u32 type, u8 vector)
+{
+	const u32 mask = INTR_INFO_VALID_MASK | INTR_INFO_INTR_TYPE_MASK |
+			 INTR_INFO_VECTOR_MASK;
+
+	return (intr_info & mask) == (INTR_INFO_VALID_MASK | type | vector);
+}
+
+static inline bool is_exception_n(u32 intr_info, u8 vector)
+{
+	return is_intr_type_n(intr_info, INTR_TYPE_HARD_EXCEPTION, vector);
+}
+
+static inline bool is_debug(u32 intr_info)
+{
+	return is_exception_n(intr_info, DB_VECTOR);
+}
+
+static inline bool is_breakpoint(u32 intr_info)
+{
+	return is_exception_n(intr_info, BP_VECTOR);
+}
+
+static inline bool is_page_fault(u32 intr_info)
+{
+	return is_exception_n(intr_info, PF_VECTOR);
+}
+
+static inline bool is_invalid_opcode(u32 intr_info)
+{
+	return is_exception_n(intr_info, UD_VECTOR);
+}
+
+static inline bool is_gp_fault(u32 intr_info)
+{
+	return is_exception_n(intr_info, GP_VECTOR);
+}
+
+static inline bool is_machine_check(u32 intr_info)
+{
+	return is_exception_n(intr_info, MC_VECTOR);
+}
+
+static inline bool is_intr_type(u32 intr_info, u32 type)
+{
+	const u32 mask = INTR_INFO_VALID_MASK | INTR_INFO_INTR_TYPE_MASK;
+
+	return (intr_info & mask) == (INTR_INFO_VALID_MASK | type);
+}
+
+static inline bool is_nmi(u32 intr_info)
+{
+	return is_intr_type(intr_info, INTR_TYPE_NMI_INTR);
+}
+
+static __always_inline void vmcs_check16(unsigned long field)
+{
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6001) == 0x2000,
+			 "16-bit accessor invalid for 64-bit field");
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6001) == 0x2001,
+			 "16-bit accessor invalid for 64-bit high field");
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6000) == 0x4000,
+			 "16-bit accessor invalid for 32-bit high field");
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6000) == 0x6000,
+			 "16-bit accessor invalid for natural width field");
+}
+
+static __always_inline void vmcs_check32(unsigned long field)
+{
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6000) == 0,
+			 "32-bit accessor invalid for 16-bit field");
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6000) == 0x6000,
+			 "32-bit accessor invalid for natural width field");
+}
+
+static __always_inline void vmcs_check64(unsigned long field)
+{
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6000) == 0,
+			 "64-bit accessor invalid for 16-bit field");
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6001) == 0x2001,
+			 "64-bit accessor invalid for 64-bit high field");
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6000) == 0x4000,
+			 "64-bit accessor invalid for 32-bit field");
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6000) == 0x6000,
+			 "64-bit accessor invalid for natural width field");
+}
+
+static __always_inline void vmcs_checkl(unsigned long field)
+{
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6000) == 0,
+			 "Natural width accessor invalid for 16-bit field");
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6001) == 0x2000,
+			 "Natural width accessor invalid for 64-bit field");
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6001) == 0x2001,
+			 "Natural width accessor invalid for 64-bit high field");
+	BUILD_BUG_ON_MSG(__builtin_constant_p(field) && ((field) & 0x6000) == 0x4000,
+			 "Natural width accessor invalid for 32-bit field");
+}
+
+asmlinkage void vmread_error(unsigned long field, bool fault);
+__attribute__((regparm(0))) void vmread_error_trampoline(unsigned long field,
+							 bool fault);
+
+static __always_inline unsigned long __vmcs_readl(unsigned long field)
+{
+	unsigned long value;
+
+	asm volatile("1: vmread %2, %1\n\t"
+		     ".byte 0x3e\n\t" /* branch taken hint */
+		     "ja 3f\n\t"
+
+		     /*
+		      * VMREAD failed.  Push '0' for @fault, push the failing
+		      * @field, and bounce through the trampoline to preserve
+		      * volatile registers.
+		      */
+		     "push $0\n\t"
+		     "push %2\n\t"
+		     "2:call vmread_error_trampoline\n\t"
+
+		     /*
+		      * Unwind the stack.  Note, the trampoline zeros out the
+		      * memory for @fault so that the result is '0' on error.
+		      */
+		     "pop %2\n\t"
+		     "pop %1\n\t"
+		     "3:\n\t"
+
+		     /* VMREAD faulted.  As above, except push '1' for @fault. */
+		     ".pushsection .fixup, \"ax\"\n\t"
+		     "4: push $1\n\t"
+		     "push %2\n\t"
+		     "jmp 2b\n\t"
+		     ".popsection\n\t"
+		     _ASM_EXTABLE(1b, 4b)
+		     : ASM_CALL_CONSTRAINT, "=r"(value) : "r"(field) : "cc");
+	return value;
+}
+
+static __always_inline u16 vmcs_read16(unsigned long field)
+{
+	vmcs_check16(field);
+	return __vmcs_readl(field);
+}
+
+static __always_inline u32 vmcs_read32(unsigned long field)
+{
+	vmcs_check32(field);
+	return __vmcs_readl(field);
+}
+
+static __always_inline u64 vmcs_read64(unsigned long field)
+{
+	vmcs_check64(field);
+	return __vmcs_readl(field);
+}
+
+static __always_inline unsigned long vmcs_readl(unsigned long field)
+{
+	vmcs_checkl(field);
+	return __vmcs_readl(field);
+}
+
+#define vmx_asm1(insn, op1, error_args...)				\
+do {									\
+	asm_volatile_goto("1: " __stringify(insn) " %0\n\t"		\
+			  ".byte 0x2e\n\t" /* branch not taken hint */	\
+			  "jna %l[error]\n\t"				\
+			  _ASM_EXTABLE(1b, %l[fault])			\
+			  : : op1 : "cc" : error, fault);		\
+	return;								\
+error:									\
+	instrumentation_begin();					\
+	insn##_error(error_args);					\
+	instrumentation_end();						\
+	return;								\
+fault:									\
+	BUG();								\
+} while (0)
+
+#define vmx_asm2(insn, op1, op2, error_args...)				\
+do {									\
+	asm_volatile_goto("1: "  __stringify(insn) " %1, %0\n\t"	\
+			  ".byte 0x2e\n\t" /* branch not taken hint */	\
+			  "jna %l[error]\n\t"				\
+			  _ASM_EXTABLE(1b, %l[fault])			\
+			  : : op1, op2 : "cc" : error, fault);		\
+	return;								\
+error:									\
+	instrumentation_begin();					\
+	insn##_error(error_args);					\
+	instrumentation_end();						\
+	return;								\
+fault:									\
+	BUG();								\
+} while (0)
+
+void vmwrite_error(unsigned long field, unsigned long value);
+void vmclear_error(struct vmcs *vmcs, u64 phys_addr);
+void vmptrld_error(struct vmcs *vmcs, u64 phys_addr);
+void invept_error(unsigned long ext, u64 eptp, gpa_t gpa);
+
+static __always_inline void __vmcs_writel(unsigned long field, unsigned long value)
+{
+	vmx_asm2(vmwrite, "r"(field), "rm"(value), field, value);
+}
+
+static __always_inline void vmcs_write16(unsigned long field, u16 value)
+{
+	vmcs_check16(field);
+	__vmcs_writel(field, value);
+}
+
+static __always_inline void vmcs_write32(unsigned long field, u32 value)
+{
+	vmcs_check32(field);
+	__vmcs_writel(field, value);
+}
+
+static __always_inline void vmcs_write64(unsigned long field, u64 value)
+{
+	vmcs_check64(field);
+	__vmcs_writel(field, value);
+}
+
+static __always_inline void vmcs_writel(unsigned long field, unsigned long value)
+{
+	vmcs_checkl(field);
+	__vmcs_writel(field, value);
+}
+
+static inline void vmcs_clear(struct vmcs *vmcs)
+{
+	u64 phys_addr = __pa(vmcs);
+	vmx_asm1(vmclear, "m"(phys_addr), vmcs, phys_addr);
+}
+
+static inline void vmcs_load(struct vmcs *vmcs)
+{
+	u64 phys_addr = __pa(vmcs);
+	vmx_asm1(vmptrld, "m"(phys_addr), vmcs, phys_addr);
+}
+
+static inline void __invept(unsigned long ext, u64 eptp, gpa_t gpa)
+{
+	struct {
+		u64 eptp, gpa;
+	} operand = {eptp, gpa};
+
+	vmx_asm2(invept, "r"(ext), "m"(operand), ext, eptp, gpa);
+}
+
+static inline void ept_sync_global(void)
+{
+	__invept(VMX_EPT_EXTENT_GLOBAL, 0, 0);
+}
+
+extern struct vmcs_config depriv_vmcs_config;
+
+static inline bool cpu_has_secondary_exec_ctrls(void)
+{
+	return depriv_vmcs_config.cpu_based_exec_ctrl &
+		CPU_BASED_ACTIVATE_SECONDARY_CONTROLS;
+}
+
+/*
+ * Track a VMCS that may be loaded on a certain CPU. If it is (cpu!=-1), also
+ * remember whether it was VMLAUNCHed, and maintain a linked list of all VMCSs
+ * loaded on this CPU (so we can clear them if the CPU goes down).
+ */
+struct loaded_vmcs {
+	struct vmcs *vmcs;
+	bool launched;
+	struct list_head loaded_vmcss_on_cpu_link;
+};
+
+#endif /* __DEPRIV_X86_VMX_H */
diff --git a/arch/x86/depriv/x86.c b/arch/x86/depriv/x86.c
new file mode 100644
index 000000000000..1683650ddadd
--- /dev/null
+++ b/arch/x86/depriv/x86.c
@@ -0,0 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Deprivilege is to run Linux kernel in VMX non-root mode
+ *
+ * Authors:
+ * 	Xin Li <fantry@gmail.com>
+ */
+
+//MODULE_LICENSE("GPL");
diff --git a/arch/x86/include/asm/depriv.h b/arch/x86/include/asm/depriv.h
index 2a82238c20dd..4c539f1a8581 100644
--- a/arch/x86/include/asm/depriv.h
+++ b/arch/x86/include/asm/depriv.h
@@ -6,6 +6,8 @@
 
 DECLARE_PER_CPU(void *, depriv_cpu_state);
 
+extern asmlinkage void asm_depriv_exit(void);
+
 struct depriv_ops {
 	bool (*enter)(void);
 	void (*exit)(void);
diff --git a/arch/x86/kvm/Kconfig b/arch/x86/kvm/Kconfig
index ad64613c4a30..331414ddf008 100644
--- a/arch/x86/kvm/Kconfig
+++ b/arch/x86/kvm/Kconfig
@@ -3,19 +3,6 @@
 # KVM configuration
 #
 
-source "virt/kvm/Kconfig"
-
-menuconfig VIRTUALIZATION
-	bool "Virtualization"
-	depends on HAVE_KVM || X86
-	default y
-	help
-	  Say Y here to get to see options for using your Linux host to run other
-	  operating systems inside virtual machines (guests).
-	  This option alone does not add any kernel code.
-
-	  If you say N, all options in this submenu will be skipped and disabled.
-
 if VIRTUALIZATION
 
 config KVM
diff --git a/arch/x86/kvm/Makefile b/arch/x86/kvm/Makefile
index 01d6528e53ef..30f244b64523 100644
--- a/arch/x86/kvm/Makefile
+++ b/arch/x86/kvm/Makefile
@@ -24,7 +24,6 @@ kvm-$(CONFIG_KVM_XEN)	+= xen.o
 kvm-intel-y		+= vmx/vmx.o vmx/vmenter.o vmx/pmu_intel.o vmx/vmcs12.o \
 			   vmx/evmcs.o vmx/nested.o vmx/posted_intr.o
 kvm-intel-$(CONFIG_X86_SGX_KVM)	+= vmx/sgx.o
-kvm-intel-$(CONFIG_KVM_INTEL_DEPRIV)	+= vmx/depriv.o vmx/depriv_entry.o vmx/depriv_handler.o vmx/depriv_validator.o
 
 kvm-amd-y		+= svm/svm.o svm/vmenter.o svm/pmu.o svm/nested.o svm/avic.o svm/sev.o
 
diff --git a/arch/x86/kvm/vmx/test_depriv.sh b/arch/x86/kvm/vmx/test_depriv.sh
deleted file mode 100755
index 9412b9d653a8..000000000000
--- a/arch/x86/kvm/vmx/test_depriv.sh
+++ /dev/null
@@ -1,17 +0,0 @@
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel intercept_msr=1
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel intercept_cr3=1
-
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel exception_bitmap=0x4000
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel exception_bitmap=0x2000
-
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel test_handle_invalid_host_state=1
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel test_handle_invalid_guest_state=1
-
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel test_early_invalid_state=0 test_handle_invalid_host_state=1 debug_host_in_non_root_mode=1 && make modules
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel test_early_invalid_state=0 test_handle_invalid_guest_state=1 debug_host_in_non_root_mode=1 && make modules
-
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel call_extra_exit_handlers=0
-sudo modprobe smep-flipor && sudo modprobe -r smep-flipor
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel
-sudo modprobe smep-flipor && sudo modprobe -r smep-flipor
-sudo modprobe -r kvm-intel && sudo modprobe kvm-intel
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index 4de4d837b3c7..539ca4e6e878 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -54,9 +54,6 @@
 
 #include "capabilities.h"
 #include "cpuid.h"
-#if IS_ENABLED(CONFIG_KVM_INTEL_DEPRIV)
-#include "depriv.h"
-#endif
 #include "evmcs.h"
 #include "hyperv.h"
 #include "kvm_onhyperv.h"
@@ -2389,10 +2386,6 @@ static void vmclear_local_loaded_vmcss(void)
 
 static void hardware_disable(void)
 {
-#if IS_ENABLED(CONFIG_KVM_INTEL_DEPRIV)
-	vmx_depriv_signal_cleanup();
-	vmx_repriv_cpu(NULL);
-#endif
 	vmclear_local_loaded_vmcss();
 
 	if (cpu_vmxoff())
@@ -8055,13 +8048,6 @@ static void vmx_exit(void)
 	synchronize_rcu();
 #endif
 
-#if IS_ENABLED(CONFIG_KVM_INTEL_DEPRIV)
-	/*
-	 * reprivilege host before kvm_exit disables VMX
-	 */
-	vmx_repriv_host();
-#endif
-
 	kvm_exit();
 
 #if IS_ENABLED(CONFIG_HYPERV)
@@ -8169,10 +8155,6 @@ static int __init vmx_init(void)
 	if (!enable_ept)
 		allow_smaller_maxphyaddr = true;
 
-#if IS_ENABLED(CONFIG_KVM_INTEL_DEPRIV)
-	vmx_depriv_host();
-#endif
-
 	return 0;
 }
 module_init(vmx_init);
diff --git a/tools/testing/selftests/depriv/test_depriv.sh b/tools/testing/selftests/depriv/test_depriv.sh
new file mode 100755
index 000000000000..c89ebe274d44
--- /dev/null
+++ b/tools/testing/selftests/depriv/test_depriv.sh
@@ -0,0 +1,17 @@
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel intercept_msr=1
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel intercept_cr3=1
+
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel exception_bitmap=0x4000
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel exception_bitmap=0x2000
+
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel test_handle_invalid_host_state=1
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel test_handle_invalid_guest_state=1
+
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel test_early_invalid_state=0 test_handle_invalid_host_state=1 debug_host_in_non_root_mode=1 && make modules
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel test_early_invalid_state=0 test_handle_invalid_guest_state=1 debug_host_in_non_root_mode=1 && make modules
+
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel call_extra_exit_handlers=0
+sudo modprobe smep-flipor && sudo modprobe -r smep-flipor
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel
+sudo modprobe smep-flipor && sudo modprobe -r smep-flipor
+sudo modprobe -r depriv-intel && sudo modprobe depriv-intel
diff --git a/virt/depriv/Kconfig b/virt/depriv/Kconfig
new file mode 100644
index 000000000000..e8687b0165d6
--- /dev/null
+++ b/virt/depriv/Kconfig
@@ -0,0 +1,5 @@
+# SPDX-License-Identifier: GPL-2.0
+# Depriv common configuration items and defaults
+
+config HAVE_DEPRIV
+       bool
diff --git a/virt/depriv/depriv_main.c b/virt/depriv/depriv_main.c
new file mode 100644
index 000000000000..25a2e8d05e70
--- /dev/null
+++ b/virt/depriv/depriv_main.c
@@ -0,0 +1,7 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Deprivilege is to run Linux in hardware guest mode
+ *
+ * Authors:
+ * 	Xin Li <fantry@gmail.com>
+ */
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index 9038f2768097..6ce518dd2103 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -5751,10 +5751,6 @@ int kvm_init(void *opaque, unsigned vcpu_size, unsigned vcpu_align,
 	r = kvm_vfio_ops_init();
 	WARN_ON(r);
 
-#if IS_ENABLED(CONFIG_KVM_INTEL_DEPRIV) // XXX: hacky
-	hardware_enable_all();
-#endif
-
 	return 0;
 
 out_unreg:
-- 
2.34.1

