From e09883dbf82e8de0a2fee3d57eb846ba12293d0a Mon Sep 17 00:00:00 2001
From: Xin Li <fantry@msn.com>
Date: Sat, 13 Nov 2021 23:47:01 -0800
Subject: [PATCH 140/140] add SPP mapping even hw doesn't have it

---
 arch/x86/depriv/vmx/depriv.c             |  2 +
 arch/x86/depriv/vmx/vmx.c                | 96 +++++++++++++++++-------
 arch/x86/depriv/vmx/vmx.h                | 12 +++
 arch/x86/include/asm/cpufeatures.h       |  1 +
 arch/x86/include/asm/vmx.h               |  3 +
 arch/x86/include/asm/vmxfeatures.h       |  1 +
 arch/x86/kernel/cpu/feat_ctl.c           |  2 +
 tools/arch/x86/include/asm/cpufeatures.h |  1 +
 8 files changed, 92 insertions(+), 26 deletions(-)

diff --git a/arch/x86/depriv/vmx/depriv.c b/arch/x86/depriv/vmx/depriv.c
index bfe208553bbc..2e63a15a821e 100644
--- a/arch/x86/depriv/vmx/depriv.c
+++ b/arch/x86/depriv/vmx/depriv.c
@@ -208,6 +208,8 @@ static inline bool init_vmcs(struct pid_namespace *ns)
 	ns->depriv_context->cpu_context[cpu] = vmcs;
 	vmcs_write64(VMCS_LINK_POINTER, ~0ull);
 	vmcs_write64(EPT_POINTER, (__pa(vmcs) + PAGE_SIZE) | VMX_EPTP_MT_WB | VMX_EPTP_PWL_4);
+	if (cpu_has_vmx_spp())
+		vmcs_write64(SPPT_POINTER, __pa(vmcs) + PAGE_SIZE * 3);
 	pr_debug("depriv: cpu%d eptp %#llx for namespace %p\n", cpu, vmcs_read64(EPT_POINTER), ns);
 
 	host_cpu_state = per_cpu(depriv_cpu_state, cpu);
diff --git a/arch/x86/depriv/vmx/vmx.c b/arch/x86/depriv/vmx/vmx.c
index bebaed357ee8..d9562e54e288 100644
--- a/arch/x86/depriv/vmx/vmx.c
+++ b/arch/x86/depriv/vmx/vmx.c
@@ -19,6 +19,9 @@
 
 #include "vmx.h"
 
+#define PT_PRESENT_MASK	(1ULL << 0)
+#define SPPT_ALLOC_ORDER	16
+
 static unsigned int __read_mostly debug_host_in_non_root_mode = 0;
 module_param(debug_host_in_non_root_mode, uint, 0444);
 
@@ -36,10 +39,12 @@ static inline bool cpu_has_load_perf_global_ctrl(void)
 	       (depriv_vmcs_config.vmexit_ctrl & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL);
 }
 
+#if 0
 static inline bool cpu_has_vmx_ept_2m_page(void)
 {
 	return depriv_vmcs_config.vmx_cap_ept & VMX_EPT_2MB_PAGE_BIT;
 }
+#endif
 
 static inline bool cpu_has_vmx_ept_1g_page(void)
 {
@@ -48,46 +53,51 @@ static inline bool cpu_has_vmx_ept_1g_page(void)
 
 inline struct vmcs *alloc_vmcs(void)
 {
-	int cpu = raw_smp_processor_id();
+	int cpu = raw_smp_processor_id(), i;
 	struct page *pages;
-	struct vmcs *vmcs;
+	struct vmcs *vmcs = NULL;
+	int alloc_order = depriv_vmcs_config.order - 9;
 	void *ept;
 	u64 *epte;
-	int i, nr_ept_pages = (1 << depriv_vmcs_config.order) - 1;
+	int nr_ept_pages = 2;
+	void *sppt;
+	u64 *sppte;
+	int nr_sppt_pages = (1 << alloc_order) - 1 - nr_ept_pages;
 
-	pages = __alloc_pages_node(cpu_to_node(cpu), GFP_ATOMIC, depriv_vmcs_config.order);
+	pages = __alloc_pages_node(cpu_to_node(cpu), GFP_ATOMIC, alloc_order);
 	if (!pages)
-		return NULL;
+		goto exit;
 
 	vmcs = page_address(pages);
-	memset(vmcs, 0, PAGE_SIZE << depriv_vmcs_config.order);
+	memset(vmcs, 0, PAGE_SIZE << alloc_order);
 	vmcs->hdr.revision_id = depriv_vmcs_config.revision_id;
 
-	if (nr_ept_pages <= 0)
-		goto exit;
-
-	ept = (void *)vmcs + PAGE_SIZE; // ept points to pgd
-
-	/* The first 1T/29G non root mode physical address space address translation */
-	epte = ept; // epte points to pgd
-	ept += PAGE_SIZE; // ept points to pud
-	--nr_ept_pages;
+	/* set up nGB physical address space address translation */
+	epte = (void *)vmcs + PAGE_SIZE; // epte points to ept l4e
+	ept = (void *)epte + PAGE_SIZE; // ept points to ept l3 page
 	epte[0] = __pa(ept) | VMX_EPT_RWX_MASK;
-	pr_debug("depriv: pgd[0]=%#llx\n",  epte[0]);
+	--nr_ept_pages;
+	pr_debug("depriv: cpu%d ept l4e[0]=%#llx\n", cpu, epte[0]);
+#if 0
+	// upto 512GB physical memory, instead of 1TB
 	if (cpu_has_vmx_ept_1g_page()) {
 		epte[1] = (__pa(ept) + PAGE_SIZE) | VMX_EPT_RWX_MASK;
-		pr_debug("depriv: pgd[1]=%#llx\n",  epte[1]);
+		pr_debug("depriv: ept l4e[1]=%#llx\n",  epte[1]);
 	}
+#endif
 
-	epte = ept; // epte points to pud
+	epte = ept; // epte points to ept l3e
 	if (cpu_has_vmx_ept_1g_page()) {
 		for (i = 0; i < 512 * nr_ept_pages; i++) {
 			epte[i] = PUD_PAGE_SIZE * i |
 				  (1ull << 7) |
-				  (MTRR_TYPE_WRBACK << VMX_EPT_MT_EPTE_SHIFT) |
-				  VMX_EPT_RWX_MASK;
-			pr_debug("depriv: ept pud[%4d]=%#llx\n", i, epte[i]);
+				  (MTRR_TYPE_WRBACK << VMX_EPT_MT_EPTE_SHIFT);
+			epte[i] |= cpu_has_vmx_spp() ?
+				   (1ull << 61) | VMX_EPT_READABLE_MASK | VMX_EPT_EXECUTABLE_MASK :
+				   VMX_EPT_RWX_MASK;
+			pr_debug("depriv: cpu%d ept l3e[%4d]=%#llx\n", cpu, i, epte[i]);
 		}
+#if 0
 	} else if (cpu_has_vmx_ept_2m_page()) {
 		ept += PAGE_SIZE; // ept points to pmd
 		--nr_ept_pages;
@@ -104,6 +114,36 @@ inline struct vmcs *alloc_vmcs(void)
 				  VMX_EPT_RWX_MASK;
 			pr_debug("depriv: ept pmd[%4d]=%#llx\n", i, epte[i]);
 		}
+#endif
+	}
+
+	sppte = ept + PAGE_SIZE; // sppte points to sppt l4e
+	sppt = (void *)sppte + PAGE_SIZE; // sppt points to sppt l3 page
+	sppte[0] = __pa(sppt) | PT_PRESENT_MASK;
+	--nr_sppt_pages;
+	pr_debug("depriv: cpu%d sppt l4e[0]=%#llx\n", cpu, sppte[0]);
+
+	sppte = sppt; // sppte points to sppt l3e
+	sppt += PAGE_SIZE; // sppt points to sppt l2 pages
+	--nr_sppt_pages;
+	for (i = 0; i < nr_sppt_pages - 1; i++) { // up to N GB physical memory
+		sppte[i] = __pa(sppt) | PT_PRESENT_MASK;
+		sppt += PAGE_SIZE;
+		pr_debug("depriv: cpu%d sppt l3e[%3d]=%#llx\n", cpu, i, sppte[i]);
+	}
+
+	pr_info("depriv: cpu%d sppt l1 page %#lx\n", cpu, __pa(sppt));
+
+	sppte = (void *)sppte + PAGE_SIZE; // sppte points to sppt l2e, and sppt to l1 page
+	for (i = 0; i < PTRS_PER_PMD * (nr_sppt_pages - 1); i++) {
+		sppte[i] = __pa(sppt) | PT_PRESENT_MASK;
+		pr_debug("depriv: cpu%d sppt l2e[%5d]=%#llx\n", cpu, i, sppte[i]);
+	}
+
+	sppte = sppt; // sppte points to sppt l1e
+	for (i = 0; i < PAGE_SIZE / 8; i++) {
+		sppte[i] = 0x5555555555555555ull;
+		pr_debug("depriv: cpu%d sppt l1e[%3d]=%#llx\n", cpu, i, sppte[i]);
 	}
 
 exit:
@@ -112,7 +152,7 @@ inline struct vmcs *alloc_vmcs(void)
 
 inline void free_vmcs(struct vmcs *vmcs)
 {
-	free_pages((unsigned long)vmcs, depriv_vmcs_config.order);
+	free_pages((unsigned long)vmcs, depriv_vmcs_config.order - 9);
 }
 
 static __init int adjust_vmx_controls(u32 ctl_min, u32 ctl_opt,
@@ -122,6 +162,7 @@ static __init int adjust_vmx_controls(u32 ctl_min, u32 ctl_opt,
 	u32 ctl = ctl_min | ctl_opt;
 
 	rdmsr(msr, vmx_msr_low, vmx_msr_high);
+	pr_debug("depriv: msr[%#08x] = %#08x:%#08x\n", msr, vmx_msr_high, vmx_msr_low);
 
 	ctl &= vmx_msr_high; /* bit == 0 in high word ==> must be zero */
 	ctl |= vmx_msr_low;  /* bit == 1 in low word  ==> must be one  */
@@ -157,7 +198,8 @@ int __init setup_vmcs_config(void)
 		opt2 = SECONDARY_EXEC_ENABLE_RDTSCP |
 		       SECONDARY_EXEC_ENABLE_EPT |
 		       SECONDARY_EXEC_ENABLE_INVPCID |
-		       SECONDARY_EXEC_XSAVES;
+		       SECONDARY_EXEC_XSAVES |
+		       SECONDARY_EXEC_ENABLE_SPP;
 		if (adjust_vmx_controls(min2, opt2,
 					MSR_IA32_VMX_PROCBASED_CTLS2,
 					&_cpu_based_2nd_exec_control) < 0)
@@ -249,9 +291,11 @@ int __init setup_vmcs_config(void)
 	 * However we need some extra pages for EPTP;
 	 */
 	if (cpu_has_vmx_ept_1g_page())
-		depriv_vmcs_config.order = 2;
-	else if (cpu_has_vmx_ept_2m_page())
-		depriv_vmcs_config.order = 5;
+		depriv_vmcs_config.order = SPPT_ALLOC_ORDER;
+#if 0
+	else if (cpu_has_vmx_ept_2m_page()) // when running on VM, i.e., nested.
+		depriv_vmcs_config.order = 6;
+#endif
 	else // No super page no EPT
 		_cpu_based_2nd_exec_control &= ~SECONDARY_EXEC_ENABLE_EPT;
 
diff --git a/arch/x86/depriv/vmx/vmx.h b/arch/x86/depriv/vmx/vmx.h
index b13654042293..795525f3cd78 100644
--- a/arch/x86/depriv/vmx/vmx.h
+++ b/arch/x86/depriv/vmx/vmx.h
@@ -319,6 +319,18 @@ static inline bool cpu_has_secondary_exec_ctrls(void)
 		CPU_BASED_ACTIVATE_SECONDARY_CONTROLS;
 }
 
+static inline bool cpu_has_vmx_ept(void)
+{
+	return depriv_vmcs_config.cpu_based_2nd_exec_ctrl &
+		SECONDARY_EXEC_ENABLE_EPT;
+}
+
+static inline bool cpu_has_vmx_spp(void)
+{
+	return depriv_vmcs_config.cpu_based_2nd_exec_ctrl &
+		SECONDARY_EXEC_ENABLE_SPP;
+}
+
 #define DEPRIV_INVALID_HOST_CR3_TARGET_COUNT	0x100000
 
 int __init setup_vmcs_config(void);
diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.h
index 6db4e2932b3d..9b4504c18e5e 100644
--- a/arch/x86/include/asm/cpufeatures.h
+++ b/arch/x86/include/asm/cpufeatures.h
@@ -230,6 +230,7 @@
 #define X86_FEATURE_FLEXPRIORITY	( 8*32+ 2) /* Intel FlexPriority */
 #define X86_FEATURE_EPT			( 8*32+ 3) /* Intel Extended Page Table */
 #define X86_FEATURE_VPID		( 8*32+ 4) /* Intel Virtual Processor ID */
+#define X86_FEATURE_SPP			( 8*32+ 5) /* Intel EPT-based Sub-Page Write Protection */
 
 #define X86_FEATURE_VMMCALL		( 8*32+15) /* Prefer VMMCALL to VMCALL */
 #define X86_FEATURE_XENPV		( 8*32+16) /* "" Xen paravirtual guest */
diff --git a/arch/x86/include/asm/vmx.h b/arch/x86/include/asm/vmx.h
index 0ffaa3156a4e..c18f3cc64030 100644
--- a/arch/x86/include/asm/vmx.h
+++ b/arch/x86/include/asm/vmx.h
@@ -70,6 +70,7 @@
 #define SECONDARY_EXEC_PT_CONCEAL_VMX		VMCS_CONTROL_BIT(PT_CONCEAL_VMX)
 #define SECONDARY_EXEC_XSAVES			VMCS_CONTROL_BIT(XSAVES)
 #define SECONDARY_EXEC_MODE_BASED_EPT_EXEC	VMCS_CONTROL_BIT(MODE_BASED_EPT_EXEC)
+#define SECONDARY_EXEC_ENABLE_SPP		VMCS_CONTROL_BIT(SPP)
 #define SECONDARY_EXEC_PT_USE_GPA		VMCS_CONTROL_BIT(PT_USE_GPA)
 #define SECONDARY_EXEC_TSC_SCALING              VMCS_CONTROL_BIT(TSC_SCALING)
 #define SECONDARY_EXEC_ENABLE_USR_WAIT_PAUSE	VMCS_CONTROL_BIT(USR_WAIT_PAUSE)
@@ -219,6 +220,8 @@ enum vmcs_field {
 	XSS_EXIT_BITMAP_HIGH            = 0x0000202D,
 	ENCLS_EXITING_BITMAP		= 0x0000202E,
 	ENCLS_EXITING_BITMAP_HIGH	= 0x0000202F,
+	SPPT_POINTER                    = 0x00002030,
+	SPPT_POINTER_HIGH               = 0x00002031,
 	TSC_MULTIPLIER                  = 0x00002032,
 	TSC_MULTIPLIER_HIGH             = 0x00002033,
 	GUEST_PHYSICAL_ADDRESS          = 0x00002400,
diff --git a/arch/x86/include/asm/vmxfeatures.h b/arch/x86/include/asm/vmxfeatures.h
index d9a74681a77d..514eea76f3bc 100644
--- a/arch/x86/include/asm/vmxfeatures.h
+++ b/arch/x86/include/asm/vmxfeatures.h
@@ -79,6 +79,7 @@
 #define VMX_FEATURE_PT_CONCEAL_VMX	( 2*32+ 19) /* "" Suppress VMX indicators in Processor Trace */
 #define VMX_FEATURE_XSAVES		( 2*32+ 20) /* "" Enable XSAVES and XRSTORS in guest */
 #define VMX_FEATURE_MODE_BASED_EPT_EXEC	( 2*32+ 22) /* "ept_mode_based_exec" Enable separate EPT EXEC bits for supervisor vs. user */
+#define VMX_FEATURE_SPP			( 2*32+ 23) /* "" Enable EPT sub-page protection */
 #define VMX_FEATURE_PT_USE_GPA		( 2*32+ 24) /* "" Processor Trace logs GPAs */
 #define VMX_FEATURE_TSC_SCALING		( 2*32+ 25) /* Scale hardware TSC when read in guest */
 #define VMX_FEATURE_USR_WAIT_PAUSE	( 2*32+ 26) /* Enable TPAUSE, UMONITOR, UMWAIT in guest */
diff --git a/arch/x86/kernel/cpu/feat_ctl.c b/arch/x86/kernel/cpu/feat_ctl.c
index da696eb4821a..534de8385a58 100644
--- a/arch/x86/kernel/cpu/feat_ctl.c
+++ b/arch/x86/kernel/cpu/feat_ctl.c
@@ -86,6 +86,8 @@ static void init_vmx_capabilities(struct cpuinfo_x86 *c)
 		set_cpu_cap(c, X86_FEATURE_VNMI);
 	if (c->vmx_capability[SECONDARY_CTLS] & VMX_F(EPT))
 		set_cpu_cap(c, X86_FEATURE_EPT);
+	if (c->vmx_capability[SECONDARY_CTLS] & VMX_F(SPP))
+		set_cpu_cap(c, X86_FEATURE_SPP);
 	if (c->vmx_capability[MISC_FEATURES] & VMX_F(EPT_AD))
 		set_cpu_cap(c, X86_FEATURE_EPT_AD);
 	if (c->vmx_capability[MISC_FEATURES] & VMX_F(VPID))
diff --git a/tools/arch/x86/include/asm/cpufeatures.h b/tools/arch/x86/include/asm/cpufeatures.h
index d5b5f2ab87a0..a35d86ce8d00 100644
--- a/tools/arch/x86/include/asm/cpufeatures.h
+++ b/tools/arch/x86/include/asm/cpufeatures.h
@@ -230,6 +230,7 @@
 #define X86_FEATURE_FLEXPRIORITY	( 8*32+ 2) /* Intel FlexPriority */
 #define X86_FEATURE_EPT			( 8*32+ 3) /* Intel Extended Page Table */
 #define X86_FEATURE_VPID		( 8*32+ 4) /* Intel Virtual Processor ID */
+#define X86_FEATURE_SPP			( 8*32+ 5) /* Intel EPT-based Sub-Page Write Protection */
 
 #define X86_FEATURE_VMMCALL		( 8*32+15) /* Prefer VMMCALL to VMCALL */
 #define X86_FEATURE_XENPV		( 8*32+16) /* "" Xen paravirtual guest */
-- 
2.34.1

